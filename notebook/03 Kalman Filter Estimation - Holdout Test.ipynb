{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dateutil import tz\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from pipedream_solver.hydraulics import SuperLink\n",
    "from pipedream_solver.simulation import Simulation\n",
    "from pipedream_solver.nutils import interpolate_sample\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Define runoff functions\n",
    "from hydrology import scs_composite_CN, scs_excess_precipitation, scs_uh_runoff, precip_data, scs_excess_precipitation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load pipedream model information \n",
    "superjunctions = pd.read_csv('../data/model_data/waller_superjunctions.csv', index_col=0)  \n",
    "superlinks = pd.read_csv('../data/model_data/waller_creek_superlinks.csv', index_col=0) \n",
    "subbasins = pd.read_csv('../data/model_data/Waller_HMS_model_data.csv', index_col=0)\n",
    "\n",
    "#### Load unit hydrograph\n",
    "# Load dimensionless unit hydrograph\n",
    "uh__dimless = pd.read_csv('../data/model_data/unit_hydrograph.csv')\n",
    "# Drop unnecessary columns and rows\n",
    "uh__dimless = uh__dimless[['time ratios', 'discharge ratios']].dropna()\n",
    "\n",
    "#### Load Forecast precipitation data\n",
    "forecast = pd.read_csv('../data/rainfall_data/precip__in_forecast_min_loc_sensor2.csv', index_col=0)\n",
    "forecast.index = pd.to_datetime(pd.Series(forecast.index))\n",
    "forecast = forecast.tz_localize('UTC')\n",
    "# Simulation params\n",
    "sample_interval = 30\n",
    "# Compute inches of precipitation for desired sample interval\n",
    "forecast_precip_in = sample_interval * forecast['precip_rate__in_per_s'].resample(f'{sample_interval}s').mean().interpolate()\n",
    "\n",
    "####Load Raw Sensor data \n",
    "Sensor1 = pd.read_csv('../data/sensor_measurements/Sensor1_classification.csv', index_col=0)\n",
    "Sensor1.index = pd.to_datetime(Sensor1.index)\n",
    "Sensor2 = pd.read_csv('../data/sensor_measurements/Sensor2_classification.csv', index_col=0)\n",
    "Sensor2.index = pd.to_datetime(Sensor2.index)\n",
    "Sensor3 = pd.read_csv('../data/sensor_measurements/Sensor3_classification.csv', index_col=0)\n",
    "Sensor3.index = pd.to_datetime(Sensor3.index)\n",
    "Sensor4 = pd.read_csv('../data/sensor_measurements/Sensor4_classification.csv', index_col=0)\n",
    "Sensor4.index = pd.to_datetime(Sensor4.index)\n",
    "\n",
    "\n",
    "#### Load Rain gauge precipitation data \n",
    "# upload LCRA data (Flow, depth, and precipitation data for the 'Waller Creek at 23rd Street' gage from the LCRA site.)\n",
    "LCRA_2022= pd.read_excel('../data/rainfall_data/LCRA_Export/LCRA_Export_2022.xlsx')[8:]\n",
    "LCRA_2023= pd.read_excel('../data/rainfall_data/LCRA_Export/LCRA_Export_2023.xlsx')[8:]\n",
    "LCRA=pd.concat([LCRA_2022[8:],LCRA_2023[8:]])\n",
    "LCRA = LCRA.set_index('Site Name')\n",
    "LCRA.index.name = 'Time'\n",
    "\n",
    "# Handle timezone\n",
    "LCRA = LCRA.tz_localize('US/Central', nonexistent='shift_forward').tz_convert('UTC')\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "LCRA = LCRA.rename(columns={'W3A' : 'depth__ft', 'W3A.1' : 'flow_rate__cfs', 'W3A.3' : 'precip_tot__in'})\n",
    "LCRA = LCRA.drop('W3A.2', axis=1)\n",
    "\n",
    "# Compute dt for each time bin\n",
    "LCRA['dt__s'] = np.roll(pd.Series(LCRA.index).diff(1).dt.seconds.values, -1)\n",
    "LCRA['dt__s'] = LCRA['dt__s'].fillna(method='ffill')\n",
    "LCRA=LCRA[LCRA['dt__s']!=0]\n",
    "\n",
    "# Compute precipitation rate from total inches and dt\n",
    "LCRA['precip_rate__in_per_s'] = LCRA['precip_tot__in'] / LCRA['dt__s']\n",
    "# Compute inches of precipitation for desired sample interval\n",
    "precip__in = sample_interval * LCRA['precip_rate__in_per_s'].astype(np.float64).resample(f'{sample_interval}s').mean().interpolate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pipedream model information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Specify simulation parameters\n",
    "# Unit conversions\n",
    "m_per_ft = 0.3048\n",
    "ft_per_mi = 5280.\n",
    "in_per_ft = 12.\n",
    "s_per_min = 60\n",
    "ns_per_s = 1e9\n",
    "\n",
    "\n",
    "site_junction_name = 'J_WLR18_COMB_HEMP'\n",
    "site_link_name = 'R_WLR16'\n",
    "site_junction_index = 14\n",
    "site_link_index = 21\n",
    "\n",
    "dt = 10\n",
    "\n",
    "# Set up Kalman filtering parameters\n",
    "n = len(superjunctions)\n",
    "p = n\n",
    "m = 2\n",
    "\n",
    "process_std_dev = 1e-2\n",
    "measurement_std_dev = 2e-4\n",
    "\n",
    "H_kal = np.zeros((m, n))\n",
    "H_kal[0, 13] = 1.\n",
    "H_kal[1, 14] = 1.\n",
    "\n",
    "Qcov = (process_std_dev**2)*np.eye(p)\n",
    "Rcov = (measurement_std_dev**2)*np.eye(m)\n",
    "\n",
    "C_kal = np.zeros((n, p))\n",
    "C_kal[np.arange(n), np.arange(p)] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute runoff into each superjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute runoff into each superjunction\n",
    "def HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: 0.):\n",
    "    keepGoing=True\n",
    "    while keepGoing:\n",
    "        try:\n",
    "            Q_in = {}\n",
    "            CNs = []\n",
    "            # Manual edits to hydrology params\n",
    "            lag_time_adjust_ratio = 1.0\n",
    "            CN_adjust_ratio = 1.0\n",
    "\n",
    "            # For each subbasin...\n",
    "            for i in range(len(subbasins)):\n",
    "                P_now = 0.\n",
    "                # Load subbasin parameters\n",
    "                CN_C = subbasins['Curve Number'][i]\n",
    "                A_Imp = subbasins['Impervious Percent'][i]\n",
    "                area__sq_mi = subbasins['Area (mi2)'][i]\n",
    "                downstream = subbasins['Downstream'][i]\n",
    "                lag_time__min = subbasins['Lag Time'][i] * lag_time_adjust_ratio\n",
    "\n",
    "                # Compute composite curve number\n",
    "                CN = scs_composite_CN(CN_C, A_Imp) * CN_adjust_ratio\n",
    "                CN = min(CN, 98)\n",
    "\n",
    "                # Compute excess precipitation\n",
    "                excess_precip_cum__in, excess_precip__in, P_now = scs_excess_precipitation(precip__in, CN,P_now,decay_function=decay_function)\n",
    "\n",
    "                # Compute runoff using unit hydrograph\n",
    "                runoff__cms = scs_uh_runoff(excess_precip__in, uh__dimless, area__sq_mi, sample_interval,lag_time__min)\n",
    "                Q_in[downstream] = runoff__cms\n",
    "\n",
    "            # Format flow input as DataFrame\n",
    "            Q_in = pd.DataFrame.from_dict(Q_in)\n",
    "            # Add flow input for missing sites\n",
    "            Q_in['UPSTREAM_WALLER'] = Q_in['R_WLR01']\n",
    "            Q_in['UPSTREAM_HEMPHILL'] = Q_in['R_HEM01']\n",
    "            Q_in[[name for name in superjunctions['name'] if not name in Q_in.columns]] = 0.\n",
    "            # Ensure flow input is only for superjunctions specified in table\n",
    "            Q_in = Q_in[superjunctions['name'].tolist()]\n",
    "            # Remove NaN values\n",
    "            Q_in = Q_in.fillna(0.)\n",
    "            # Copy flow input with original timestamps\n",
    "            Q_in_orig = Q_in.copy()\n",
    "            # Convert flow input index to integer index starting with zero\n",
    "            Q_in.index = Q_in.index.astype(int) / 1e9\n",
    "            Q_in.index -= Q_in.index.min()\n",
    "            keepGoing=False\n",
    "        \n",
    "        except ValueError:\n",
    "            keepGoing=True\n",
    "        except KeyError :\n",
    "            keepGoing=True\n",
    "        except AssertionError:\n",
    "            keepGoing=True\n",
    "\n",
    "\n",
    "    return excess_precip__in,Q_in,P_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the threshold-based EKF model - rain gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 10.2% [1220.38 s]"
     ]
    }
   ],
   "source": [
    "\n",
    "codisp = {}\n",
    "# Create array for detected outliers\n",
    "is_outlier = []\n",
    "is_outliers = []\n",
    "# Create a dict to store anomaly score of each point\n",
    "avg_codisp = {}\n",
    "\n",
    "start_date='20220627'\n",
    "end_date='20230520'\n",
    "\n",
    "final_data={}\n",
    "P_now = 0\n",
    "\n",
    "\n",
    "precip__in = precip__in.loc[start_date:end_date]\n",
    "\n",
    "if precip__in.empty != True:\n",
    "    excess_precip__in,Q_in,P_now=HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: (1 -0.9965)*x)\n",
    "    #For holdout assessment - only we assimilated Sensor 1, Sensor 2 data. \n",
    "    measurements = pd.concat([Sensor1['Sensor1'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                              Sensor2['Sensor2'].resample('5min').mean().interpolate(method='nearest')\n",
    "                             ], axis=1).interpolate()\n",
    "    measurements = measurements.fillna(method='backfill')\n",
    "    measurements = measurements + superjunctions.loc[[13, 14], 'z_inv'].values\n",
    "    measurements.index = measurements.index - precip__in.index.min()\n",
    "    measurements.index = measurements.index.astype(int) / 1e9  \n",
    "\n",
    "\n",
    "    superlink = SuperLink(superlinks, superjunctions,internal_links=30, mobile_elements=True)\n",
    "\n",
    "\n",
    "    H_j = []\n",
    "    h_Ik = []\n",
    "    Q_uk = []\n",
    "    Q_dk = []\n",
    "    residuals = []\n",
    "    scores = []\n",
    "\n",
    "    # Set constant timestep (in seconds)\n",
    "\n",
    "    # Add constant baseflow\n",
    "    baseflow = 0.5e-3 * np.ones(superlink._h_Ik.size)\n",
    "\n",
    "    # Create simulation context manager\n",
    "    with Simulation(superlink, Q_in=Q_in, Qcov=Qcov, Rcov=Rcov,\n",
    "                C=C_kal, H=H_kal, interpolation_method='nearest') as simulation:\n",
    "        simulation.model.load_state(final_data)\n",
    "        # While simulation time has not expired...\n",
    "        while simulation.t <= simulation.t_end:\n",
    "            # Step model forward in time\n",
    "            simulation.step(dt=dt, num_iter=8, Q_Ik=baseflow)\n",
    "            # Get measured value\n",
    "            next_measurement = interpolate_sample(simulation.t,\n",
    "                                                  measurements.index.values,\n",
    "                                                  measurements.values,\n",
    "                                                  method=0)\n",
    "            # Apply Kalman filter with measured value\n",
    "            #prediction step \n",
    "            H = H_kal\n",
    "            C = C_kal\n",
    "            Z_next = next_measurement\n",
    "            P_x_k_k = simulation.P_x_k_k\n",
    "            A_1, A_2, b = simulation.model._semi_implicit_system(_dt=dt)\n",
    "            I = np.eye(A_1.shape[0])\n",
    "            y_k1_k = b\n",
    "            A_1_inv = np.linalg.inv(A_1)\n",
    "            H_1 = H @ A_1_inv\n",
    "            #Anomaly rejection step \n",
    "            residual = (Z_next - H_1 @ y_k1_k)\n",
    "            residuals.append(residual)\n",
    "\n",
    "            cond = residual**2 > 0.5\n",
    "\n",
    "            if (cond).any():\n",
    "                H_mod = H[~cond]\n",
    "                H_1 = H_mod @ A_1_inv\n",
    "                Rcov_mod = Rcov[~cond][:, ~cond]\n",
    "                Z_next = Z_next[~cond]\n",
    "            else:\n",
    "                H_mod = H\n",
    "                Rcov_mod = Rcov\n",
    "                \n",
    "            #Update step \n",
    "            P_y_k1_k = A_2 @ P_x_k_k @ A_2.T + C @ Qcov @ C.T\n",
    "            L_y_k1 = P_y_k1_k @ H_1.T @ np.linalg.inv((H_1 @ P_y_k1_k @ H_1.T) + Rcov_mod)\n",
    "            P_y_k1_k1 = (I - L_y_k1 @ H_1) @ P_y_k1_k\n",
    "            b_hat = y_k1_k + L_y_k1 @ (Z_next - H_1 @ y_k1_k)\n",
    "            P_x_k1_k1 = A_1_inv @ P_y_k1_k1 @ A_1_inv.T\n",
    "            #if score < 1e-7:\n",
    "            simulation.P_x_k_k = P_x_k1_k1\n",
    "            simulation.model.b = b_hat\n",
    "            simulation.model.iter_count -= 1\n",
    "            simulation.model.t -= dt\n",
    "            simulation.model._solve_step(dt=dt)\n",
    "\n",
    "            #simulation.kalman_filter(next_measurement, dt=dt)\n",
    "            simulation.model.reposition_junctions()\n",
    "            # Print progress bar\n",
    "            simulation.print_progress()\n",
    "            # Save states\n",
    "            H_j.append(simulation.model.H_j.copy())\n",
    "            h_Ik.append(simulation.model.h_Ik.copy())\n",
    "            Q_uk.append(simulation.model.Q_uk.copy())\n",
    "            Q_dk.append(simulation.model.Q_dk.copy())\n",
    "\n",
    "    time_index = pd.date_range(start=excess_precip__in.index.min(), \n",
    "                                       periods=len(H_j), \n",
    "                                       freq=f'{dt}s')\n",
    "\n",
    "    # Convert saved states to dataframes\n",
    "    H_j = pd.DataFrame(np.vstack(H_j), index=time_index, columns=superjunctions['name'])\n",
    "    h_Ik = pd.DataFrame(np.vstack(h_Ik), index=time_index)\n",
    "    Q_uk = pd.DataFrame(np.vstack(Q_uk), index=time_index, columns=superlinks['name'])\n",
    "    Q_dk = pd.DataFrame(np.vstack(Q_dk), index=time_index, columns=superlinks['name'])\n",
    "    residuals = pd.DataFrame(np.vstack(residuals), index=time_index, columns=['J_WLR16_32ND', 'J_WLR18_COMB_HEMP'\n",
    "                                                                ])\n",
    "\n",
    "\n",
    "    # Compute depth\n",
    "    h_j = H_j - simulation.model._z_inv_j\n",
    "    final_data=simulation.model.states\n",
    "\n",
    "    final_data['t']=0\n",
    "\n",
    "\n",
    "\n",
    "h_j_kf = h_j.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show model_kf simulation results and residuals  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_junction_name = 'J_WLR18_COMB_HEMP'\n",
    "site_junction_index = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "Sensor2['Sensor2'].plot(ax=ax, c='r')\n",
    "h_j[site_junction_name].plot(ax=ax, label='model', c='b')\n",
    "plt.xlim(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "(residuals**2)[site_junction_name].plot(ax=ax, marker='o')\n",
    "plt.xlim(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_j_kf['J_WLR16_32ND'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h1_gauge_holdout.csv')\n",
    "h_j_kf['J_WLR19_23RD'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h3_gauge_holdout.csv')\n",
    "h_j_kf['J_WLR20_TRINITY'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h4_gauge_holdout.csv')\n",
    "h_j_kf['J_WLR18_COMB_HEMP'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h2_gauge_holdout.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the threshold-based EKF model - forecasted rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codisp = {}\n",
    "# Create array for detected outliers\n",
    "is_outlier = []\n",
    "is_outliers = []\n",
    "# Create a dict to store anomaly score of each point\n",
    "avg_codisp = {}\n",
    "\n",
    "start_date='20230303'\n",
    "end_date='20230520'\n",
    "\n",
    "\n",
    "\n",
    "final_data={}\n",
    "P_now = 0\n",
    "\n",
    "\n",
    "precip__in = forecast_precip_in.loc[start_date:end_date]\n",
    "\n",
    "if precip__in.empty != True:\n",
    "    excess_precip__in,Q_in,P_now=HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: (1 -0.9965)*x)\n",
    "    #For holdout assessment - only we assimilated Sensor 1, Sensor 2 data. \n",
    "    measurements = pd.concat([Sensor1['Sensor1'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                              Sensor2['Sensor2'].resample('5min').mean().interpolate(method='nearest')\n",
    "                             ], axis=1).interpolate()\n",
    "    measurements = measurements.fillna(method='backfill')\n",
    "    measurements = measurements + superjunctions.loc[[13, 14], 'z_inv'].values\n",
    "    measurements.index = measurements.index - precip__in.index.min()\n",
    "    measurements.index = measurements.index.astype(int) / 1e9  \n",
    "\n",
    "\n",
    "    superlink = SuperLink(superlinks, superjunctions,internal_links=30, mobile_elements=True)\n",
    "\n",
    "\n",
    "    H_j = []\n",
    "    h_Ik = []\n",
    "    Q_uk = []\n",
    "    Q_dk = []\n",
    "    residuals = []\n",
    "    scores = []\n",
    "\n",
    "    # Set constant timestep (in seconds)\n",
    "\n",
    "    # Add constant baseflow\n",
    "    baseflow = 0.5e-3 * np.ones(superlink._h_Ik.size)\n",
    "\n",
    "    # Create simulation context manager\n",
    "    with Simulation(superlink, Q_in=Q_in, Qcov=Qcov, Rcov=Rcov,\n",
    "                C=C_kal, H=H_kal, interpolation_method='nearest') as simulation:\n",
    "        simulation.model.load_state(final_data)\n",
    "        # While simulation time has not expired...\n",
    "        while simulation.t <= simulation.t_end:\n",
    "            # Step model forward in time\n",
    "            simulation.step(dt=dt, num_iter=8, Q_Ik=baseflow)\n",
    "            # Get measured value\n",
    "            next_measurement = interpolate_sample(simulation.t,\n",
    "                                                  measurements.index.values,\n",
    "                                                  measurements.values,\n",
    "                                                  method=0)\n",
    "            # Apply Kalman filter with measured value\n",
    "            #prediction step \n",
    "            H = H_kal\n",
    "            C = C_kal\n",
    "            Z_next = next_measurement\n",
    "            P_x_k_k = simulation.P_x_k_k\n",
    "            A_1, A_2, b = simulation.model._semi_implicit_system(_dt=dt)\n",
    "            I = np.eye(A_1.shape[0])\n",
    "            y_k1_k = b\n",
    "            A_1_inv = np.linalg.inv(A_1)\n",
    "            H_1 = H @ A_1_inv\n",
    "            #Anomaly rejection step \n",
    "            residual = (Z_next - H_1 @ y_k1_k)\n",
    "            residuals.append(residual)\n",
    "\n",
    "            cond = residual**2 > 0.5\n",
    "\n",
    "            if (cond).any():\n",
    "                H_mod = H[~cond]\n",
    "                H_1 = H_mod @ A_1_inv\n",
    "                Rcov_mod = Rcov[~cond][:, ~cond]\n",
    "                Z_next = Z_next[~cond]\n",
    "            else:\n",
    "                H_mod = H\n",
    "                Rcov_mod = Rcov\n",
    "                \n",
    "            #Update step \n",
    "            P_y_k1_k = A_2 @ P_x_k_k @ A_2.T + C @ Qcov @ C.T\n",
    "            L_y_k1 = P_y_k1_k @ H_1.T @ np.linalg.inv((H_1 @ P_y_k1_k @ H_1.T) + Rcov_mod)\n",
    "            P_y_k1_k1 = (I - L_y_k1 @ H_1) @ P_y_k1_k\n",
    "            b_hat = y_k1_k + L_y_k1 @ (Z_next - H_1 @ y_k1_k)\n",
    "            P_x_k1_k1 = A_1_inv @ P_y_k1_k1 @ A_1_inv.T\n",
    "            #if score < 1e-7:\n",
    "            simulation.P_x_k_k = P_x_k1_k1\n",
    "            simulation.model.b = b_hat\n",
    "            simulation.model.iter_count -= 1\n",
    "            simulation.model.t -= dt\n",
    "            simulation.model._solve_step(dt=dt)\n",
    "\n",
    "            #simulation.kalman_filter(next_measurement, dt=dt)\n",
    "            simulation.model.reposition_junctions()\n",
    "            # Print progress bar\n",
    "            simulation.print_progress()\n",
    "            # Save states\n",
    "            H_j.append(simulation.model.H_j.copy())\n",
    "            h_Ik.append(simulation.model.h_Ik.copy())\n",
    "            Q_uk.append(simulation.model.Q_uk.copy())\n",
    "            Q_dk.append(simulation.model.Q_dk.copy())\n",
    "\n",
    "    time_index = pd.date_range(start=excess_precip__in.index.min(), \n",
    "                                       periods=len(H_j), \n",
    "                                       freq=f'{dt}s')\n",
    "\n",
    "    # Convert saved states to dataframes\n",
    "    H_j = pd.DataFrame(np.vstack(H_j), index=time_index, columns=superjunctions['name'])\n",
    "    h_Ik = pd.DataFrame(np.vstack(h_Ik), index=time_index)\n",
    "    Q_uk = pd.DataFrame(np.vstack(Q_uk), index=time_index, columns=superlinks['name'])\n",
    "    Q_dk = pd.DataFrame(np.vstack(Q_dk), index=time_index, columns=superlinks['name'])\n",
    "    residuals = pd.DataFrame(np.vstack(residuals), index=time_index, columns=['J_WLR16_32ND', 'J_WLR18_COMB_HEMP'\n",
    "                                                                ])\n",
    "\n",
    "\n",
    "    # Compute depth\n",
    "    h_j = H_j - simulation.model._z_inv_j\n",
    "    final_data=simulation.model.states\n",
    "\n",
    "    final_data['t']=0\n",
    "\n",
    "\n",
    "\n",
    "h_j_kf = h_j.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_j_kf['J_WLR16_32ND'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h1_forecast_holdout.csv')\n",
    "h_j_kf['J_WLR18_COMB_HEMP'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h2_forecast_holdout.csv')\n",
    "h_j_kf['J_WLR19_23RD'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h3_forecast_holdout.csv')\n",
    "h_j_kf['J_WLR20_TRINITY'].to_csv('../data/result/digital_twin_model_result/h_j_kf_h4_forecast_holdout.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
