{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import quadprog\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "import time\n",
    "import schedule\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.tomorrow.io/v4/timelines?location=42.3478%2C%20-71.0466&fields=temperature&units=metric&timesteps=1h&startTime=now&endTime=nowPlus6h&apikey=VYLHerX2Zbk6nBvVo4VTkpGg2JFJTfw3\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Encoding\": \"gzip\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "('location', '30.2955535, -97.7398146'),#Hemphillpark2 \n",
    "('location', '30.3359239, -97.7126299'),#highland \n",
    "('location', '30.3081971, -97.7278405'),#shipe neighbor \n",
    "('location', '30.2858333, -97.7338333'),#bridge3 \n",
    "('location', '30.2834167, -97.7344444'),#bridge4\n",
    "('location', '30.2871667, -97.7341111'),#bridge5\n",
    "('location', '30.2879080, -97.7341380'),#Campus2\n",
    "('location', '30.2885374, -97.7346483'),#bridge6\n",
    "('location', '30.2886667, -97.7337500'),#bridge2\n",
    "('location', '30.2905109, -97.7305199'),#Eastwoods neighborhood \n",
    "('location', '30.2949913, -97.7394333'),#Hempillpark3\n",
    "('location', '30.3129327, -97.7337902'),#Triangle pond\n",
    "('location', '30.3004298, -97.7245227'),#Hancock receation center\n",
    "('location', '30.3213002, -97.7230546'),#Chesterfield\n",
    "('location', '30.3265250, -97.7199113'),#Relly pond\n",
    "('location', '30.3337866, -97.7140881'),#Kenniston\n",
    "('location', '30.3412541, -97.7150030'),#Crestland Triangle\n",
    "('location', '30.2924810, -97.7363710'),#Campus1\n",
    "('location', '30.2914444, -97.7353333')]#bridge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=[('location', '30.28412, -97.73118'), #PRC\n",
    "('location', '30.2978508, -97.7390084')] #Hemphillpark \n",
    "\n",
    "\n",
    "fields=[('fields', 'precipitationProbability'),\n",
    "('fields', 'rainIntensity')]\n",
    "\n",
    "timesteps=[('timesteps', '1d'),('timesteps', '1h')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tomorrow_API_forecast_data(i):\n",
    "    set_location=location[i]\n",
    "    for j in range(0, len(fields)):\n",
    "        set_field=fields[j]\n",
    "        for k in range(0, len(timesteps)):\n",
    "            set_timestep=timesteps[k]\n",
    "            pre_raindata=pd.read_csv(\"/Users/future_water_system/Desktop/crawling/raindata.csv\")\n",
    "            # set file name - define i,j,k \n",
    "            if k == 0:\n",
    "                name_timestep = '1d'\n",
    "            elif k == 1:\n",
    "                name_timestep ='1h'\n",
    "\n",
    "            if j == 0:\n",
    "                name_field= 'probability'\n",
    "            elif j ==1:\n",
    "                name_field='intensity'\n",
    "\n",
    "            date_value=datetime.now().strftime('%Y%m%d')\n",
    "            time_value=datetime.now().strftime('%H%M%S')\n",
    "\n",
    "            params = (set_location,set_field,set_timestep,('units', 'metric'),('apikey', 'VYLHerX2Zbk6nBvVo4VTkpGg2JFJTfw3'),)\n",
    "            headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Accept-Encoding\": \"gzip\"}\n",
    "\n",
    "            response = requests.get('https://api.tomorrow.io/v4/timelines', params=params, headers=headers)\n",
    "            time.sleep(10)\n",
    "\n",
    "            #change to dictionary format\n",
    "            content=response.content\n",
    "            dict_str = content.decode(\"UTF-8\")\n",
    "            my_data = ast.literal_eval(dict_str)\n",
    "            sub=my_data\n",
    "\n",
    "            rain_data = pd.DataFrame([[date_value,time_value,set_location,name_field,name_timestep,sub]],columns=['date','time','loc','field','timestep','value'])\n",
    "            now_raindata=pd.concat([pre_raindata,rain_data])\n",
    "            now_raindata.to_csv(\"/Users/future_water_system/Desktop/crawling/raindata.csv\", index=False)\n",
    "\n",
    "\n",
    "                        \n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomorrow.io API https://docs.tomorrow.io/reference/get-timelines\n",
    "# use schedule module to do work\n",
    "\n",
    "\n",
    "\n",
    "def adaptive_crawling(i):\n",
    "    loc=location[i]\n",
    "    params = (\n",
    "            loc,\n",
    "            ('fields', 'precipitationProbability'),\n",
    "            ('timesteps', '1d'),\n",
    "            ('units', 'metric'),\n",
    "            ('apikey', 'VYLHerX2Zbk6nBvVo4VTkpGg2JFJTfw3'),)\n",
    "    headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Encoding\": \"gzip\"}\n",
    "\n",
    "    response = requests.get('https://api.tomorrow.io/v4/timelines', params=params, headers=headers)\n",
    "\n",
    "    #change to dictionary format\n",
    "    content=response.content\n",
    "    dict_str = content.decode(\"UTF-8\")\n",
    "    my_data = ast.literal_eval(dict_str)\n",
    "    sub=my_data\n",
    "    sub=sub['data']['timelines']\n",
    "\n",
    "    sub_str=sub[0]\n",
    "    interval=sub_str['intervals']\n",
    "\n",
    "    #Select value in dictionbary \n",
    "    rainStartTime=[]\n",
    "    value=np.zeros((len(interval),))\n",
    "\n",
    "    for i in range(0,len(interval)):\n",
    "        interval_str=interval[i]\n",
    "        rainStartTime.append(interval_str['startTime'])\n",
    "        value[i]=interval_str['values']['precipitationProbability']\n",
    "        \n",
    "        return rainStartTime[0],value[0]\n",
    "        \n",
    "\n",
    "\n",
    "def crawling_job():\n",
    "    \n",
    "    while(True):\n",
    "\n",
    "    for i in range(0,len(location)):\n",
    "\n",
    "        today_date,today_rainprob=adaptive_crawling(i)\n",
    "\n",
    "        if today_rainprob >= 10:\n",
    "            \n",
    "            collect_tomorrow_API_forecast_data(i)\n",
    "\n",
    "    time.sleep(3600)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Adaptive crawling -pretest for collecting date \n",
    "schedule.every().day.at(\"00:00\").do(crawling_job) \n",
    "     \n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
