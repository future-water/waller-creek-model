{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "sns.set_palette('husl')\n",
    "\n",
    "from pipedream_solver.hydraulics import SuperLink\n",
    "from pipedream_solver.simulation import Simulation\n",
    "from pipedream_solver.nutils import interpolate_sample\n",
    "\n",
    "import influxdb \n",
    "from dateutil import tz\n",
    "\n",
    "import ast\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Define runoff functions\n",
    "from hydrology import scs_composite_CN, scs_excess_precipitation, scs_uh_runoff, precip_data, scs_excess_precipitation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Load pipedream model information \n",
    "superjunctions = pd.read_csv('../data/model_data/waller_superjunctions.csv', index_col=0)  \n",
    "superlinks = pd.read_csv('../data/model_data/waller_creek_superlinks.csv', index_col=0) \n",
    "subbasins = pd.read_csv('../data/model_data/Waller_HMS_model_data.csv', index_col=0)\n",
    "\n",
    "#### Load unit hydrograph\n",
    "# Load dimensionless unit hydrograph\n",
    "uh__dimless = pd.read_csv('../data/model_data/unit_hydrograph.csv')\n",
    "# Drop unnecessary columns and rows\n",
    "uh__dimless = uh__dimless[['time ratios', 'discharge ratios']].dropna()\n",
    "\n",
    "#### Load Forecast precipitation data\n",
    "forecast = pd.read_csv('../data/rainfall_data/precip__in_forecast_min_loc_sensor2.csv', index_col=0)\n",
    "forecast.index = pd.to_datetime(pd.Series(forecast.index))\n",
    "forecast = forecast.tz_localize('UTC')\n",
    "# Simulation params\n",
    "sample_interval = 30\n",
    "# Compute inches of precipitation for desired sample interval\n",
    "forecast_precip_in = sample_interval * forecast['precip_rate__in_per_s'].resample(f'{sample_interval}s').mean().interpolate()\n",
    "\n",
    "\n",
    "####Load Raw Sensor data \n",
    "Sensor1 = pd.read_csv('../data/sensor_measurements/Sensor1_classification.csv', index_col=0)\n",
    "Sensor1.index = pd.to_datetime(Sensor1.index)\n",
    "Sensor2 = pd.read_csv('../data/sensor_measurements/Sensor2_classification.csv', index_col=0)\n",
    "Sensor2.index = pd.to_datetime(Sensor2.index)\n",
    "Sensor3 = pd.read_csv('../data/sensor_measurements/Sensor3_classification.csv', index_col=0)\n",
    "Sensor3.index = pd.to_datetime(Sensor3.index)\n",
    "Sensor4 = pd.read_csv('../data/sensor_measurements/Sensor4_classification.csv', index_col=0)\n",
    "Sensor4.index = pd.to_datetime(Sensor4.index)\n",
    "\n",
    "\n",
    "#### Load Rain gauge precipitation data \n",
    "# upload LCRA data (Flow, depth, and precipitation data for the 'Waller Creek at 23rd Street' gage from the LCRA site.)\n",
    "LCRA_2022= pd.read_excel('../data/rainfall_data/LCRA_Export/LCRA_Export_2022.xlsx')[8:]\n",
    "LCRA_2023= pd.read_excel('../data/rainfall_data/LCRA_Export/LCRA_Export_2023.xlsx')[8:]\n",
    "LCRA=pd.concat([LCRA_2022[8:],LCRA_2023[8:]])\n",
    "LCRA = LCRA.set_index('Site Name')\n",
    "LCRA.index.name = 'Time'\n",
    "\n",
    "# Handle timezone\n",
    "LCRA = LCRA.tz_localize('US/Central', nonexistent='shift_forward').tz_convert('UTC')\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "LCRA = LCRA.rename(columns={'W3A' : 'depth__ft', 'W3A.1' : 'flow_rate__cfs', 'W3A.3' : 'precip_tot__in'})\n",
    "LCRA = LCRA.drop('W3A.2', axis=1)\n",
    "\n",
    "# Compute dt for each time bin\n",
    "LCRA['dt__s'] = np.roll(pd.Series(LCRA.index).diff(1).dt.seconds.values, -1)\n",
    "LCRA['dt__s'] = LCRA['dt__s'].fillna(method='ffill')\n",
    "LCRA=LCRA[LCRA['dt__s']!=0]\n",
    "\n",
    "# Compute precipitation rate from total inches and dt\n",
    "LCRA['precip_rate__in_per_s'] = LCRA['precip_tot__in'] / LCRA['dt__s']\n",
    "# Compute inches of precipitation for desired sample interval\n",
    "precip__in = sample_interval * LCRA['precip_rate__in_per_s'].astype(np.float64).resample(f'{sample_interval}s').mean().interpolate()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify simulation parameters\n",
    "# Unit conversions\n",
    "m_per_ft = 0.3048\n",
    "ft_per_mi = 5280.\n",
    "in_per_ft = 12.\n",
    "s_per_min = 60\n",
    "ns_per_s = 1e9\n",
    "\n",
    "\n",
    "site_junction_name = 'J_WLR18_COMB_HEMP'\n",
    "site_link_name = 'R_WLR16'\n",
    "site_junction_index = 14\n",
    "site_link_index = 21\n",
    "\n",
    "dt = 10\n",
    "\n",
    "# Set up Kalman filtering parameters\n",
    "n = len(superjunctions)\n",
    "p = n\n",
    "m = 4\n",
    "\n",
    "process_std_dev = 1e-2\n",
    "measurement_std_dev = 2e-4\n",
    "\n",
    "H_kal = np.zeros((m, n))\n",
    "H_kal[0, 13] = 1.\n",
    "H_kal[1, 14] = 1.\n",
    "H_kal[2, 15] = 1.\n",
    "H_kal[3, 16] = 1.\n",
    "Qcov = (process_std_dev**2)*np.eye(p)\n",
    "Rcov = (measurement_std_dev**2)*np.eye(m)\n",
    "\n",
    "C_kal = np.zeros((n, p))\n",
    "C_kal[np.arange(n), np.arange(p)] = 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute runoff into each superjunction\n",
    "def HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: 0.):\n",
    "    keepGoing=True\n",
    "    while keepGoing:\n",
    "        try:\n",
    "            Q_in = {}\n",
    "            CNs = []\n",
    "            # Manual edits to hydrology params\n",
    "            lag_time_adjust_ratio = 1.0\n",
    "            CN_adjust_ratio = 1.0\n",
    "\n",
    "\n",
    "            # For each subbasin...\n",
    "            for i in range(len(subbasins)):\n",
    "                Pnow = P_now\n",
    "                # Load subbasin parameters\n",
    "                CN_C = subbasins['Curve Number'][i]\n",
    "                A_Imp = subbasins['Impervious Percent'][i]\n",
    "                area__sq_mi = subbasins['Area (mi2)'][i]\n",
    "                downstream = subbasins['Downstream'][i]\n",
    "                lag_time__min = subbasins['Lag Time'][i] * lag_time_adjust_ratio\n",
    "\n",
    "                # Compute composite curve number\n",
    "                CN = scs_composite_CN(CN_C, A_Imp) * CN_adjust_ratio\n",
    "                CN = min(CN, 98)\n",
    "\n",
    "                # Compute excess precipitation\n",
    "                excess_precip_cum__in, excess_precip__in, P_now = scs_excess_precipitation(precip__in, CN,Pnow,decay_function=decay_function)\n",
    "\n",
    "                # Compute runoff using unit hydrograph\n",
    "                runoff__cms = scs_uh_runoff(excess_precip__in, uh__dimless, area__sq_mi, sample_interval,lag_time__min)\n",
    "                Q_in[downstream] = runoff__cms\n",
    "\n",
    "            # Format flow input as DataFrame\n",
    "            Q_in = pd.DataFrame.from_dict(Q_in)\n",
    "            # Add flow input for missing sites\n",
    "            Q_in['UPSTREAM_WALLER'] = Q_in['R_WLR01']\n",
    "            Q_in['UPSTREAM_HEMPHILL'] = Q_in['R_HEM01']\n",
    "            Q_in[[name for name in superjunctions['name'] if not name in Q_in.columns]] = 0.\n",
    "            # Ensure flow input is only for superjunctions specified in table\n",
    "            Q_in = Q_in[superjunctions['name'].tolist()]\n",
    "            # Remove NaN values\n",
    "            Q_in = Q_in.fillna(0.)\n",
    "            # Copy flow input with original timestamps\n",
    "            Q_in_orig = Q_in.copy()\n",
    "            # Convert flow input index to integer index starting with zero\n",
    "            Q_in.index = Q_in.index.astype(int) / 1e9\n",
    "            Q_in.index -= Q_in.index.min()\n",
    "            keepGoing=False\n",
    "        \n",
    "        except ValueError:\n",
    "            keepGoing=True\n",
    "        except KeyError :\n",
    "            keepGoing=True\n",
    "        except AssertionError:\n",
    "            keepGoing=True\n",
    "\n",
    "\n",
    "    return excess_precip__in,Q_in,P_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation without KF\n",
    "def Model_simulation(excess_precip__in,Q_in,dt,superlinks,superjunctions,measurements,load_data,stop_kf_time):\n",
    "    \n",
    "    keepGoing=True\n",
    "    while keepGoing:\n",
    "        try:\n",
    "\n",
    "            superlink = SuperLink(superlinks, superjunctions,internal_links=30, mobile_elements=True)\n",
    "            \n",
    "\n",
    "            H_j = []\n",
    "            h_Ik = []\n",
    "            Q_uk = []\n",
    "            Q_dk = []\n",
    "            residuals = []\n",
    "            scores = []\n",
    "\n",
    "            # Set constant timestep (in seconds)\n",
    "\n",
    "            # Add constant baseflow\n",
    "#             baseflow = 0.35e-3 * np.ones(superlink._h_Ik.size)\n",
    "            baseflow = 0.5e-3 * np.ones(superlink._h_Ik.size)\n",
    "\n",
    "            # Create simulation context manager\n",
    "            with Simulation(superlink, Q_in=Q_in, Qcov=Qcov, Rcov=Rcov,\n",
    "                        C=C_kal, H=H_kal, interpolation_method='nearest') as simulation:\n",
    "                simulation.model.load_state(load_data)\n",
    "                # While simulation time has not expired...\n",
    "                while simulation.t <= simulation.t_end:\n",
    "                    # Step model forward in time\n",
    "                    simulation.step(dt=dt, num_iter=8, Q_Ik=baseflow)\n",
    "                    # Get measured value\n",
    "                    cond_kf = simulation.t < stop_kf_time\n",
    "                    if cond_kf:\n",
    "                        next_measurement = interpolate_sample(simulation.t,\n",
    "                                                          measurements.index.values,\n",
    "                                                          measurements.values,\n",
    "                                                          method=0)\n",
    "                        # Apply Kalman filter with measured value\n",
    "                        # prediction step \n",
    "                        H = H_kal\n",
    "                        C = C_kal\n",
    "                        Z_next = next_measurement\n",
    "                        P_x_k_k = simulation.P_x_k_k\n",
    "                        A_1, A_2, b = simulation.model._semi_implicit_system(_dt=dt)\n",
    "                        I = np.eye(A_1.shape[0])\n",
    "                        y_k1_k = b\n",
    "                        A_1_inv = np.linalg.inv(A_1)\n",
    "                        H_1 = H @ A_1_inv\n",
    "                        #anomaly detection step \n",
    "                        residual = (Z_next - H_1 @ y_k1_k)\n",
    "                        residuals.append(residual)\n",
    "                        cond = residual**2 > 0.5\n",
    "\n",
    "\n",
    "                        if (cond).any():\n",
    "                            H_mod = H[~cond]\n",
    "                            H_1 = H_mod @ A_1_inv\n",
    "                            Rcov_mod = Rcov[~cond][:, ~cond]\n",
    "                            Z_next = Z_next[~cond]\n",
    "                        else:\n",
    "                            H_mod = H\n",
    "                            Rcov_mod = Rcov\n",
    "                        #update step \n",
    "                        P_y_k1_k = A_2 @ P_x_k_k @ A_2.T + C @ Qcov @ C.T\n",
    "                        L_y_k1 = P_y_k1_k @ H_1.T @ np.linalg.inv((H_1 @ P_y_k1_k @ H_1.T) + Rcov_mod)\n",
    "                        P_y_k1_k1 = (I - L_y_k1 @ H_1) @ P_y_k1_k\n",
    "                        b_hat = y_k1_k + L_y_k1 @ (Z_next - H_1 @ y_k1_k)\n",
    "                        P_x_k1_k1 = A_1_inv @ P_y_k1_k1 @ A_1_inv.T\n",
    "                        #if score < 1e-7:\n",
    "                        simulation.P_x_k_k = P_x_k1_k1\n",
    "                        simulation.model.b = b_hat\n",
    "                        simulation.model.iter_count -= 1\n",
    "                        simulation.model.t -= dt\n",
    "                        simulation.model._solve_step(dt=dt)\n",
    "\n",
    "                    #simulation.kalman_filter(next_measurement, dt=dt)\n",
    "                    simulation.model.reposition_junctions()\n",
    "                    # Print progress bar\n",
    "                    simulation.print_progress()\n",
    "                    # Save states\n",
    "                    H_j.append(simulation.model.H_j.copy())\n",
    "                    h_Ik.append(simulation.model.h_Ik.copy())\n",
    "                    Q_uk.append(simulation.model.Q_uk.copy())\n",
    "                    Q_dk.append(simulation.model.Q_dk.copy())\n",
    "\n",
    "            time_index = pd.date_range(start=excess_precip__in.index.min(), \n",
    "                                               periods=len(H_j), \n",
    "                                               freq=f'{dt}s')\n",
    "\n",
    "            # Convert saved states to dataframes\n",
    "            H_j = pd.DataFrame(np.vstack(H_j), index=time_index, columns=superjunctions['name'])\n",
    "            h_Ik = pd.DataFrame(np.vstack(h_Ik), index=time_index)\n",
    "            Q_uk = pd.DataFrame(np.vstack(Q_uk), index=time_index, columns=superlinks['name'])\n",
    "            Q_dk = pd.DataFrame(np.vstack(Q_dk), index=time_index, columns=superlinks['name'])\n",
    "            \n",
    "\n",
    "            # Compute depth\n",
    "            h_j = H_j - simulation.model._z_inv_j\n",
    "\n",
    "            final_data=simulation.model.states\n",
    "\n",
    "            keepGoing=False\n",
    "        \n",
    "        except ValueError:\n",
    "            keepGoing=True\n",
    "        except KeyError :\n",
    "            keepGoing=True\n",
    "        except AssertionError:\n",
    "            keepGoing=True\n",
    "    \n",
    "    return H_j,h_Ik,Q_uk,Q_dk,h_j,final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_raingauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Kalman Filter Apply\n",
    "stop_kf_time = 0\n",
    "start_date_raingauge='20220627 00:00:00'\n",
    "end_date_raingauge='20230521 00:00:00'\n",
    "\n",
    "precip__in= precip__in.loc[start_date_raingauge:end_date_raingauge]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P_now = 0\n",
    "final_data={}\n",
    "if precip__in.empty != True:\n",
    "    excess_precip__in,Q_in,P_now=HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: (1 - 0.9965)*x)\n",
    "\n",
    "    \n",
    "    measurements = pd.concat([Sensor1['Sensor1'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                              Sensor2['Sensor2'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                          Sensor3['Sensor3'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                          Sensor4['Sensor4'].resample('5min').mean().interpolate(method='nearest')\n",
    "                             ], axis=1).interpolate()\n",
    "    measurements = measurements.fillna(method='backfill')\n",
    "    measurements = measurements + superjunctions.loc[[13, 14, 15, 16], 'z_inv'].values\n",
    "    measurements.index = measurements.index - precip__in.index.min()\n",
    "    measurements.index = measurements.index.astype(int) / 1e9    \n",
    "    H_j,h_Ik,Q_uk,Q_dk,h_j,final_data=Model_simulation(excess_precip__in,Q_in,dt,superlinks,superjunctions,measurements,final_data,stop_kf_time)\n",
    "    final_data['t']=0\n",
    "    \n",
    "h_j_gauge = h_j.copy()\n",
    "Q_uk_gauge = Q_uk.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Kalman Filter Apply\n",
    "stop_kf_time=0 \n",
    "start_date_forecast='20220627 00:00:00'\n",
    "end_date_forecast='20230521 00:00:00'\n",
    "\n",
    "precip__in= forecast_precip_in.loc[start_date_forecast:end_date_forecast]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_now = 0\n",
    "final_data={}\n",
    "if precip__in.empty != True:\n",
    "    excess_precip__in,Q_in,P_now=HydrologyModel(precip__in,subbasins,P_now,decay_function=lambda x: (1 - 0.9965)*x)\n",
    "\n",
    "    measurements = pd.concat([Sensor1['Sensor1'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                              Sensor2['Sensor2'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                          Sensor3['Sensor3'].resample('5min').mean().interpolate(method='nearest'),\n",
    "                          Sensor4['Sensor4'].resample('5min').mean().interpolate(method='nearest')\n",
    "                             ], axis=1).interpolate()\n",
    "    measurements = measurements.fillna(method='backfill')\n",
    "    measurements = measurements + superjunctions.loc[[13, 14, 15, 16], 'z_inv'].values\n",
    "    measurements.index = measurements.index - precip__in.index.min()\n",
    "    measurements.index = measurements.index.astype(int) / 1e9    \n",
    "    H_j,h_Ik,Q_uk,Q_dk,h_j,final_data=Model_simulation(excess_precip__in,Q_in,dt,superlinks,superjunctions,measurements,final_data,stop_kf_time)\n",
    "    final_data['t']=0\n",
    "\n",
    "h_j_forecast = h_j.copy()\n",
    "Q_uk_forecast = Q_uk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "site_junction_name = 'J_WLR16_32ND'\n",
    "site_junction_index = 13\n",
    "fig, ax = plt.subplots(1,figsize=(18, 7))\n",
    "ax.plot(Sensor1['Sensor1'], c='tab:orange', label='Sensor1', zorder=5 )\n",
    "\n",
    "h_j_forecast.loc['20220627 00:00:00':'20230520 00:00:00', site_junction_name].plot(ax=ax, label='model forecast', c='c', alpha=0.7, zorder=5)\n",
    "h_j_gauge[site_junction_name].plot(ax=ax, label='model gauge', c='blue', alpha=0.7)\n",
    "plt.xlim('20220627 00:00:00', '20230520 00:00:00')\n",
    "plt.ylim(0, 1.2)\n",
    "\n",
    "plt.legend( fontsize='13')\n",
    "plt.xticks(rotation=0,ha='center', fontsize='13')\n",
    "plt.yticks( fontsize='13')\n",
    "plt.ylabel('Depth(m)', fontsize='13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h_j_gauge['J_WLR16_32ND'].to_csv('../data/result/base_model_result/h_j_h1_gauge.csv')\n",
    "h_j_gauge['J_WLR18_COMB_HEMP'].to_csv('../data/result/base_model_result/h_j_h2_gauge.csv')\n",
    "h_j_gauge['J_WLR19_23RD'].to_csv('../data/result/base_model_result/h_j_h3_gauge.csv')\n",
    "h_j_gauge['J_WLR20_TRINITY'].to_csv('../data/result/base_model_result/h_j_h4_gauge.csv')\n",
    "\n",
    "h_j_forecast['J_WLR16_32ND'].to_csv('../data/result/base_model_result/h_j_h1_forecast.csv')\n",
    "h_j_forecast['J_WLR18_COMB_HEMP'].to_csv('../data/result/base_model_result/h_j_h2_forecast.csv')\n",
    "h_j_forecast['J_WLR19_23RD'].to_csv('../data/result/base_model_result/h_j_h3_forecast.csv')\n",
    "h_j_forecast['J_WLR20_TRINITY'].to_csv('../data/result/base_model_result/h_j_h4_forecast.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
